path:
    train_path: /opt/ml/input/data/train_dataset/
    test_path: /opt/ml/input/data/test_dataset/

data:
    shuffle: True
    augmentation: # adea, bt 등등
    
model:
    model_name: klue/roberta-small
    saved_name: roberta-small

train:
    seed: 42
    gpus: 1
    batch_size: 16
    max_epoch: 10
    logging_step: 1
    
optimizer:
    learning_rate: 1e-5
    optimizer_name: AdamW
    lr_weight_decay: False
    lr_decay_step: 20
    lr_sch_use: False
    scheduler_name: constant_warmup # StepLR, ReduceLROnPlateau, CosineAnnealingLR, constant_warmup

loss:
    loss_name: CrossEntropy # CrossEntropy, focal, label_smoothing, f1

fold:
    fold: False
    nums_folds: 5

sweep:
    method: bayes
    lr_min: 1e-6
    lr_max: 1e-4
    name: klue/roberta-small
    count: 5

wandb:
    wandb_username: seokhee
    wandb_project: mrc_temp
    wandb_entity: mrc_et
